# -*- coding: utf-8 -*-

# -- Network Analysis --

# # Data Meet-up CorrelaidXBremen - Network Analysis in Python
# 06.05.21 and 03.06.21
# 
# We will try to recreate the R code from the meet-up in November last year in Python. Code (within Rmd) and presentation (html) are in this [Repository](https://github.com/christine-hvw/sna_intro-datameetup).
# 
# *-> To access the presentation directly go [here](https://rawcdn.githack.com/christine-hvw/sna_intro-datameetup/985435a1ad276ff926b8a2b258b6bc70cacd848b/sna_intro.html#some-basics-of-network-analysis).*
# 
# ## To Do:
# - Legenden hinzufÃ¼gen
# - Interaktive Visualisierung


# ## The Basics
# 
# Let's first recap what we learned last time [here](https://rawcdn.githack.com/christine-hvw/sna_intro-datameetup/985435a1ad276ff926b8a2b258b6bc70cacd848b/sna_intro.html#some-basics-of-network-analysis) in the section "Network Analysis in *R*". 
# 
# We will not reproduce that part but dive right into the applied case.


# ## Application: Co-authorship Networks
# ### First: Get the data


# Libraries
import networkx as nx #THE module for network analysis
import matplotlib.pyplot as plt #plotting
from pyvis.network import Network #interactive plotting
import pandas as pd #working with data frames
import numpy as np #math
%matplotlib inline

soc_bipart = pd.read_csv("socpub_bipart.csv", index_col=0)

# It's an incidence matrix (or a bipartite layout)
soc_bipart

# Unique number of publications authored
soc_bipart.T.sum().value_counts().sort_index()
# -> 657 people have authored 1 publication

# ### Make it a Graph object


# First: convert to matrix type
soc_inc = soc_bipart.to_numpy()

# Transpose into adjacency matrix (authors x authors)
# .dot = multiplication, .T = transpose matrix
soc_adj = (np.dot(soc_inc, soc_inc.T)).astype(int)

# Remove self loops
np.fill_diagonal(soc_adj, 0)

# Now NetworkX can make a Graph
soc_1mode = nx.from_numpy_matrix(soc_adj)

# Relabel the nodes from integers to author names
names = soc_bipart.index
numbers = list(range(len(names)))

auth_name_dict = dict(zip(numbers, names)) # relabel function needs dictionary input
print("Author - name dictionary:\n", auth_name_dict)

soc_1mode = nx.relabel_nodes(soc_1mode, auth_name_dict)

# Print info about graph
print("Graph info:\n", nx.info(soc_1mode))
print("Nodes (with attributes):\n", soc_1mode.nodes(data=True))
print("Edges (with attributes):\n", soc_1mode.edges(data=True))
#print("Edges weight>1:", list((u,v) for u,v,e in soc_1mode.edges(data=True) if e['weight']>1))

# ### A first plot
# 
# Not very helpful yet...


# set size of plot area
plt.figure(figsize=(20,20))

# basic function with random layout
nx.draw(soc_1mode, with_labels=True)

# ### Add node attributes
# Let's give our authors some attributes. I have handcoded *department membership* (dep*), *gender* (female), or being in a *leading position* (al, agl) for all members of the SOCIUM research center.


# Read in the data
auth_att = pd.read_excel("auth_attributes.xlsx", index_col="name")
auth_att

# #### Data wrangling


# indicator for socium membership
auth_att["socium"] = auth_att["dep_cat"].apply(lambda x: 1 if x > 0 else 0)

# label department membership
# this is convenient with a dictionary
dep_dict = {1: "Theory",  
             2: "Polit. Economy",
             3: "Ineq. in Welfare Societies",
             4: "Life Course",
             5: "Health",
             6: "Methods"}

auth_att["dep_cat"] = auth_att["dep_cat"].replace(dep_dict)

auth_att

# #### Make dictionaries
# We'll make dictionaries from the attributes we want to attach to the network because it's the required format for the attaching function.
# 
# `to_dict()` takes as key values the data frame's index, here: the author names.


auth_soc_dict = auth_att["socium"].to_dict()
auth_dep_dict = auth_att["dep_cat"].to_dict()
auth_fem_dict = auth_att["female"].to_dict()
auth_head_dict = auth_att["al"].to_dict()

# Looks like this
auth_dep_dict

# #### Add attributes to graph
# With `set_node_attributes()` attributes are attached to the nodes (corresponding function for edges).


# Add attributes to graph
nx.set_node_attributes(soc_1mode, auth_soc_dict, "socium")
nx.set_node_attributes(soc_1mode, auth_dep_dict, "dep_cat")
nx.set_node_attributes(soc_1mode, auth_fem_dict, "female")
nx.set_node_attributes(soc_1mode, auth_head_dict, "dep_head")

soc_1mode.nodes.data()

# #### Centrality measures
# Centrality measures of nodes are a - lol - *central* part of network analysis. There are a myriad of different measures. For a brief description of the most important ones see the presentation in *R* or [Wikipedia](https://en.wikipedia.org/wiki/Centrality)


# Degree centrality (normalized by default, otherwise use G.degree(G.nodes))
degree_dict = nx.degree_centrality(soc_1mode)
# Betweenness centrality
between_dict = nx.betweenness_centrality(soc_1mode, normalized=True)
# Eigenvector centrality
eigen_dict = nx.eigenvector_centrality(soc_1mode)

# Add to nodes
nx.set_node_attributes(soc_1mode, degree_dict, "degree")
nx.set_node_attributes(soc_1mode, between_dict, "betweenness")
nx.set_node_attributes(soc_1mode, eigen_dict, "eigenvector")

list(soc_1mode.nodes.data())

# ### More (and better) plotting
# 
# First: remove non-Socium members to reduce network.


# make list of nodes to remove
remove = [node for node,soc in auth_soc_dict.items() if soc != 1]

# make copy of network
soc_sub = soc_1mode

#remove
soc_sub.remove_nodes_from(remove)

print(nx.info(soc_sub))
print(soc_sub.nodes.data("degree"))

# #### Degree centrality


# Labels conditional on degree
labs_deg = {} #dictionary
# make keys (names) of top 10 degree authors also the value in the dictionary
for n,d in sorted(soc_sub.nodes.data("degree"), key=lambda x: x[1], reverse=True)[0:10]:
    labs_deg[n] = n

plt.figure(figsize=(20,20))
plt.title("Degree Centrality")
nx.draw(
        soc_sub, 
        # increase node size
        node_size = [d * 10000 + 50 for n,d in soc_sub.nodes.data("degree")],
        # continuous color scale according to degree, cmap = color option
        node_color = [d for n,d in soc_sub.nodes.data("degree")], cmap = plt.cm.GnBu,
        # color of node circles
        edgecolors = "gray",
        # color of edges
        edge_color = "gainsboro",
        alpha = .8,
        labels = labs_deg,
        # position layout algorithm with options: k=optim. distance, it. = max. iterations
        pos=nx.spring_layout(soc_sub, k=0.3, iterations=100)
        )


# #### Betweenness centrality


# Labels conditional on betweenness
labs_bet = {} 
for n,d in sorted(soc_sub.nodes.data("betweenness"), key=lambda x: x[1], reverse=True)[0:10]:
    labs_bet[n] = n

plt.figure(figsize=(20,20))
plt.title("Betweenness Centrality")
nx.draw(
        soc_sub, 
        node_size = [d * 10000 + 50 for n,d in soc_sub.nodes.data("betweenness")],
        node_color = [d for n,d in soc_sub.nodes.data("betweenness")], cmap = "YlOrRd",
        node_shape = "s",
        edgecolors = "gray",
        edge_color = "gainsboro",
        width = [w for e,f,w in soc_sub.edges.data("weight")],
        alpha = .8,
        labels = labs_bet,
        pos=nx.spring_layout(soc_sub, k=0.3, iterations=100)
        )

# #### Eigenvector centrality


# Labels conditional on eigenvector
labs_eig = {} 
for n,d in sorted(soc_sub.nodes.data("eigenvector"), key=lambda x: x[1], reverse=True)[0:5]:
    labs_eig[n] = n

# Fix layout, need to set seed for plotting elements separately
pos = nx.spring_layout(soc_sub, k=0.3, iterations=100, seed=200)

plt.figure(figsize=(20,20))
plt.title("Eigenvector Centrality")

nx.draw_networkx_nodes(
                       soc_sub, 
                       node_size = [d * 10000 + 50 for n,d in soc_sub.nodes.data("eigenvector")],
                       node_color = [d for n,d in soc_sub.nodes.data("eigenvector")], 
                       cmap = plt.cm.viridis_r,
                       node_shape = "^",
                       edgecolors = "gray",
                       alpha = 0.8,
                       pos=pos
                       )

nx.draw_networkx_edges(
                       soc_sub,
                       edge_color = [w for e,f,w in soc_sub.edges.data("weight")], 
                       edge_cmap = plt.cm.inferno_r,
                       width = 2,
                       alpha = 1,
                       pos=pos
                       )

nx.draw_networkx_labels(
                        soc_sub,
                        labels = labs_eig,
                        font_family = "monospace",
                        font_weight= "bold",
                        horizontalalignment = "right",
                        alpha=.8,
                        pos = pos
                        )
plt.show()

# #### Centrality distributions


fig, axs = plt.subplots(nrows = 1, ncols = 3, sharey=False, figsize = (20,4))

bins = 50

axs[0].set_title("Degree centrality")
axs[0].hist([m for n,m in soc_sub.nodes.data("degree")], bins=bins)

axs[1].set_title("Betweenness centrality")
axs[1].hist([m for n,m in soc_sub.nodes.data("betweenness")], bins=bins)

axs[2].set_title("Eigenvector centrality")
axs[2].hist([m for n,m in soc_sub.nodes.data("eigenvector")], bins=bins)

plt.show()

# #### Clustering
# 
# https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.cluster.clustering.html#networkx.algorithms.cluster.clustering


# Add clustering coefficents to graph
nx.set_node_attributes(soc_1mode, nx.clustering(soc_1mode), "clustering")

soc_sub = soc_1mode

soc_sub.remove_nodes_from(remove)

print(soc_sub.nodes.data("clustering"))

# Labels conditional on complete clustering
labs_clu = {} 
for n,d in soc_sub.nodes.data("clustering"):
     if d == 1:
         labs_clu[n] = n 

plt.figure(figsize=(20,20))
plt.title("Clustering")

nx.draw(
        soc_sub, 
        node_size = [d*500 + 50 for n,d in soc_sub.nodes.data("clustering")],
        node_color = [d for n,d in soc_sub.nodes.data("clustering")], cmap = plt.cm.YlGn_r,
        edgecolors = "gray",
        edge_color = "gainsboro",
        width = [w for e,f,w in soc_sub.edges.data("weight")],
        alpha = .8,
        labels = labs_clu,
        pos=nx.spring_layout(soc_sub, k=0.4, iterations=100)
        )

# #### Assortativity/Homophily
# 
# Let's look at whether co-authorship happens more often within departments (=department assortativity/homophily).
# 
# First a visual inspection:


# Make authors and departments a data frame
dep_df = pd.DataFrame(soc_sub.nodes.data("dep_cat"), columns=["name", "dep_cat"]).set_index("name")
# Turn into categorical type
dep_df["dep_cat"] = pd.Categorical(dep_df["dep_cat"])

# Plot
plt.figure(figsize=(20,20))
plt.title("Department Assortativity")

nx.draw(
        soc_sub, 
        node_size = 100,
        # turn string categories into numerical codes
        node_color = [c for c in dep_df["dep_cat"].cat.codes], 
        cmap = plt.cm.Set3,
        edgecolors = "gray",
        edge_color = "gainsboro",
        width = [w for e,f,w in soc_sub.edges.data("weight")],
        alpha = .8,
        pos=nx.spring_layout(soc_sub, k=0.4, iterations=100)
        )

# The assortativity coefficient (-1 to +1, with -1/+1=complete dis/assortativity) supports the visual impression. Membership in the same department fosters co-authorship.


print(nx.attribute_assortativity_coefficient(soc_sub, "dep_cat"))

# Co-authorhsip is independent of gender though:


print(nx.attribute_assortativity_coefficient(soc_sub, "female"))

# ### More plotting options
# 
# - https://pyvis.readthedocs.io/en/latest/tutorial.html
# - https://github.com/benmaier/netwulf/
# - https://towardsdatascience.com/introducing-jaal-interacting-with-network-made-easy-124173bb4fa
# - https://plotly.com/python/network-graphs/


# 
# ### PyVis


from IPython.display import HTML
net = Network(notebook=True)
net.from_nx(soc_1mode)
net.toggle_physics(True)
net.show_buttons(filter_=['physics'])
html_graph = net.show("example.html")

type(html_graph)





